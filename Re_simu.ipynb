{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df7c9378-ada1-4353-8443-63f286dd8090",
   "metadata": {},
   "source": [
    "## 环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c463d9aa-2cee-461e-b824-19948e8b898f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "系统 CPU 核心数: 20\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "# 如果提示没有 tqdm，请先运行 !pip install tqdm\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "# --- 1. 环境配置: 强制单线程 ---\n",
    "# 在并行计算中，每个子进程内部不要再进行多线程运算(OpenMP)，\n",
    "# 否则会造成 CPU 上下文切换频繁，反而变慢。\n",
    "NUM_THREADS = 1 \n",
    "os.environ[\"OMP_NUM_THREADS\"]      = str(NUM_THREADS)\n",
    "os.environ[\"MKL_NUM_THREADS\"]      = str(NUM_THREADS)\n",
    "os.environ[\"OPENBIAS_NUM_THREADS\"] = str(NUM_THREADS)\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(NUM_THREADS)\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"]  = str(NUM_THREADS)\n",
    "\n",
    "# 检测系统核心数\n",
    "NUM_CPU = os.cpu_count()\n",
    "if NUM_CPU is None: NUM_CPU = 4\n",
    "print(f'系统 CPU 核心数: {NUM_CPU}')\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2912149-7cca-46dc-97e2-d0a57d190500",
   "metadata": {},
   "source": [
    "##  数据生成工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd36fec7-ce2e-4353-a924-5182da99a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_true_gen(N, p, K, gamma):\n",
    "    '''生成真实参数'''\n",
    "    np.random.seed(0)  \n",
    "    beta_true = np.zeros([p+1, K-1])\n",
    "    for k in range(K-1):\n",
    "        beta_true[:,k] = np.random.normal(size=[p+1,]) \n",
    "        beta_true[:,k] = beta_true[:,k] / np.linalg.norm(beta_true[:,k])\n",
    "    # 模拟稀有类截距 (截距变得很小，使得概率很低)\n",
    "    beta_true[0,:] = beta_true[0,:] + gamma * np.log(N)\n",
    "    return beta_true\n",
    "\n",
    "def X_gen(N, p=5, rho=0.5):\n",
    "    '''生成特征矩阵 X'''\n",
    "    mean = np.zeros(p)\n",
    "    # 构造协方差矩阵\n",
    "    cov = np.zeros([p,p])\n",
    "    for i in range(p):\n",
    "        for j in range(i,p):\n",
    "            cov[i,j] = rho**(np.abs(i-j))\n",
    "    cov = cov + cov.T - np.eye(p)        \n",
    "    X = np.random.multivariate_normal(mean, cov, (N,)) \n",
    "    return X\n",
    "\n",
    "def get_onehot(y, baseclass=None):\n",
    "    '''One-hot 编码'''\n",
    "    idx = np.squeeze(y)\n",
    "    ss = len(y)\n",
    "    nclass = len(np.unique(y))\n",
    "    z = np.zeros([ss, nclass])\n",
    "    z[np.arange(ss), idx] = 1  \n",
    "    ls_class = list(np.arange(nclass))\n",
    "    if baseclass is not None:\n",
    "        _ = ls_class.pop(baseclass)\n",
    "    return z[:, ls_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cbefd8-d186-4ce2-9132-c417fd592f47",
   "metadata": {},
   "source": [
    "## 定义求解器 (Solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eea6473-79f0-4ffb-8238-4f8112c28584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mle_multilogistic_opt_ic(x, y, K0_pval, baseclass=None): \n",
    "    '''全局最大似然 GMLE (Newton-Raphson algorithm)'''\n",
    "    ss, ncov = x.shape  \n",
    "    K = len(np.unique(y))    \n",
    "    y_onehot = get_onehot(y, baseclass) \n",
    "    dist = 1.0; niter = 0\n",
    "    beta0 = np.zeros([ncov*(K-1),1])  \n",
    "    alpha0 = np.log((1/K0_pval-1)/(K-1)) \n",
    "    beta0[np.arange(K-1)*ncov] = alpha0 \n",
    "    \n",
    "    while (dist > 1.0e-6) & (niter < 50):\n",
    "        niter += 1\n",
    "        beta0mat = (beta0.reshape([(K-1),ncov]).T) * 1.0\n",
    "        link_mu = x @ beta0mat  \n",
    "        prob = np.exp(link_mu)\n",
    "        prob = prob / (1 + np.sum(prob, axis=1, keepdims=True))\n",
    "        resid = y_onehot - prob\n",
    "        D1 = ((x.T @ resid/ss).T.flatten()).reshape([-1,1]) \n",
    "        \n",
    "        Xrep = x.reshape([1,ss,ncov]) * np.ones([K-1,1,1]) \n",
    "        XMAT = (prob.T).reshape([K-1,ss,1]) * Xrep  \n",
    "        XMAT = (XMAT.transpose([1,0,2])).reshape([ss,-1])  \n",
    "        D2 = -(XMAT.T @ XMAT/ss)  \n",
    "        \n",
    "        for i in range(K-1):    \n",
    "            probtmp = (prob[:,i]) * 1.0\n",
    "            weight = np.sqrt(probtmp*(1-probtmp))\n",
    "            wx = weight.reshape([ss,1]) * x\n",
    "            D2[i*ncov:(i+1)*ncov, i*ncov:(i+1)*ncov] = wx.T @ wx/ss   \n",
    "\n",
    "        step = (np.linalg.inv(D2 + 1.0e-6*np.eye(ncov*(K-1)))) @ D1   \n",
    "        beta1 = beta0 + step\n",
    "        dist = np.mean(np.abs(beta1 - beta0))\n",
    "        beta0 = beta1\n",
    "    return beta0.reshape([(K-1),ncov]).T, dist, niter  \n",
    "\n",
    "def gd_multilogistic_opt_ic(x, y, K0_pval, baseclass, alpha): \n",
    "    '''全局最大似然 GMLE (Gradient Descent algorithm)'''\n",
    "    ss, ncov = x.shape  \n",
    "    K = len(np.unique(y)) \n",
    "    y_onehot = get_onehot(y, baseclass) \n",
    "    dist = 1.0; niter = 0\n",
    "    beta0 = np.zeros([ncov*(K-1),1]) \n",
    "    alpha0 = np.log((1/K0_pval-1)/(K-1))\n",
    "    beta0[np.arange(K-1)*ncov] = alpha0\n",
    "    \n",
    "    while (dist > 1.0e-6) & (niter < 1000):\n",
    "        niter += 1\n",
    "        beta0mat = (beta0.reshape([(K-1),ncov]).T) * 1.0\n",
    "        link_mu = x @ beta0mat  \n",
    "        prob = np.exp(link_mu)\n",
    "        prob = prob / (1 + np.sum(prob, axis=1, keepdims=True))\n",
    "        resid = y_onehot - prob\n",
    "        D1 = ((x.T @ resid/ss).T).reshape([-1,1])\n",
    "        beta1 = beta0 + alpha * D1\n",
    "        dist = np.mean(np.abs(beta1 - beta0))\n",
    "        beta0 = beta1\n",
    "    return beta0.reshape([(K-1),ncov]).T, dist, niter\n",
    "\n",
    "def solve_single_pair_joblib(X_major, Y_major, X_rare, Y_rare, K0_pval):\n",
    "    \"\"\"\n",
    "    PMLE 的并行子任务函数 (Window/Linux 通用)\n",
    "    只计算 Major Class (0) 和特定的 Rare Class (k)\n",
    "    \"\"\"\n",
    "    # 1. 拼接数据：将 Major Class 和当前的 Rare Class 拼在一起\n",
    "    x_sub = np.vstack([X_major, X_rare])\n",
    "    \n",
    "    # 构造二分类标签: Major设为0, Rare设为1\n",
    "    n_major = len(Y_major)\n",
    "    n_rare = len(Y_rare)\n",
    "    y_sub = np.concatenate([np.zeros(n_major), np.ones(n_rare)]).reshape(-1, 1)\n",
    "    \n",
    "    # 2. 二分类 Newton-Raphson 求解\n",
    "    ss, ncov = x_sub.shape\n",
    "    dist = 1.0\n",
    "    niter = 0\n",
    "    \n",
    "    # 初始化参数\n",
    "    beta0 = np.zeros([ncov, 1])\n",
    "    alpha0 = np.log(1/K0_pval - 1)\n",
    "    beta0[0] = alpha0\n",
    "    \n",
    "    # 迭代优化\n",
    "    while (dist > 1.0e-6) & (niter < 50):\n",
    "        niter += 1\n",
    "        link_mu = x_sub @ beta0\n",
    "        \n",
    "        # Sigmoid 函数\n",
    "        prob = 1.0 / (1.0 + np.exp(-link_mu))\n",
    "        \n",
    "        resid = y_sub - prob\n",
    "        D1 = x_sub.T @ resid / ss\n",
    "        \n",
    "        # Hessian 矩阵\n",
    "        weight = np.sqrt(prob * (1 - prob))\n",
    "        wx = weight * x_sub\n",
    "        # 显式删除大变量释放内存\n",
    "        del weight\n",
    "        D2 = wx.T @ wx / ss + 1.0e-6 * np.eye(ncov)\n",
    "        del wx\n",
    "        \n",
    "        # 更新\n",
    "        step = np.linalg.inv(D2) @ D1\n",
    "        beta1 = beta0 + step\n",
    "        dist = np.mean(np.abs(beta1 - beta0))\n",
    "        beta0 = beta1\n",
    "        \n",
    "    return beta1.reshape([ncov,])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5113ff74-9fd2-46d0-a36f-a24b2a7991fd",
   "metadata": {},
   "source": [
    "## 主仿真循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dacd9392-c0a3-44bb-b2a2-32d18bf1b0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 开始仿真 ===\n",
      "设置: N=100000, K=11, p=10, Rounds=50\n",
      "并行后端: Joblib (loky), Workers=10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe45cf7735e43dcaec0426bc5f1f640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Simulation Progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1: PMLE=0.889s | NR=0.975s | GD=3.162s\n",
      "Round 2: PMLE=0.379s | NR=2.182s | GD=28.155s\n",
      "Round 3: PMLE=0.454s | NR=1.888s | GD=12.589s\n",
      "Round 4: PMLE=0.449s | NR=2.446s | GD=6.224s\n",
      "Round 5: PMLE=0.435s | NR=2.598s | GD=6.212s\n",
      "Round 6: PMLE=0.442s | NR=2.101s | GD=25.231s\n",
      "Round 7: PMLE=0.461s | NR=1.874s | GD=25.038s\n",
      "Round 8: PMLE=0.436s | NR=2.299s | GD=6.495s\n",
      "Round 9: PMLE=0.331s | NR=2.196s | GD=5.595s\n",
      "Round 10: PMLE=0.313s | NR=1.827s | GD=26.503s\n",
      "Round 11: PMLE=0.338s | NR=2.204s | GD=25.722s\n",
      "Round 12: PMLE=0.470s | NR=2.782s | GD=26.601s\n",
      "Round 13: PMLE=0.423s | NR=2.593s | GD=11.990s\n",
      "Round 14: PMLE=0.425s | NR=1.811s | GD=26.497s\n",
      "Round 15: PMLE=0.409s | NR=2.723s | GD=5.848s\n",
      "Round 16: PMLE=0.425s | NR=2.201s | GD=26.642s\n",
      "Round 17: PMLE=0.457s | NR=2.479s | GD=29.164s\n",
      "Round 18: PMLE=0.419s | NR=2.787s | GD=6.845s\n",
      "Round 19: PMLE=0.314s | NR=2.582s | GD=6.543s\n",
      "Round 20: PMLE=0.407s | NR=2.493s | GD=29.353s\n",
      "Round 21: PMLE=0.328s | NR=2.399s | GD=6.955s\n",
      "Round 22: PMLE=0.421s | NR=1.912s | GD=7.784s\n",
      "Round 23: PMLE=0.415s | NR=2.559s | GD=28.997s\n",
      "Round 24: PMLE=0.302s | NR=2.447s | GD=6.623s\n",
      "Round 25: PMLE=0.394s | NR=2.450s | GD=27.648s\n",
      "Round 26: PMLE=0.413s | NR=2.308s | GD=7.786s\n",
      "Round 27: PMLE=0.419s | NR=2.162s | GD=28.650s\n",
      "Round 28: PMLE=0.296s | NR=2.475s | GD=27.925s\n",
      "Round 29: PMLE=0.417s | NR=2.276s | GD=5.747s\n",
      "Round 30: PMLE=0.421s | NR=2.317s | GD=5.978s\n",
      "Round 31: PMLE=0.317s | NR=2.552s | GD=27.199s\n",
      "Round 32: PMLE=0.410s | NR=2.094s | GD=8.579s\n",
      "Round 33: PMLE=0.411s | NR=2.037s | GD=27.081s\n",
      "Round 34: PMLE=0.413s | NR=2.443s | GD=6.344s\n",
      "Round 35: PMLE=0.328s | NR=2.463s | GD=6.605s\n",
      "Round 36: PMLE=0.427s | NR=2.243s | GD=6.386s\n",
      "Round 37: PMLE=0.430s | NR=1.932s | GD=5.952s\n",
      "Round 38: PMLE=0.398s | NR=2.465s | GD=6.041s\n",
      "Round 39: PMLE=0.402s | NR=2.485s | GD=27.075s\n",
      "Round 40: PMLE=0.413s | NR=2.071s | GD=27.162s\n",
      "Round 41: PMLE=0.403s | NR=2.109s | GD=6.466s\n",
      "Round 42: PMLE=0.432s | NR=2.024s | GD=6.151s\n",
      "Round 43: PMLE=0.308s | NR=2.168s | GD=27.765s\n",
      "Round 44: PMLE=0.418s | NR=2.008s | GD=8.412s\n",
      "Round 45: PMLE=0.425s | NR=1.997s | GD=17.647s\n",
      "Round 46: PMLE=0.402s | NR=2.393s | GD=6.594s\n",
      "Round 47: PMLE=0.393s | NR=2.420s | GD=27.180s\n",
      "Round 48: PMLE=0.399s | NR=2.022s | GD=27.106s\n",
      "Round 49: PMLE=0.425s | NR=2.415s | GD=7.048s\n",
      "Round 50: PMLE=0.421s | NR=2.183s | GD=6.514s\n",
      "\n",
      "==================================================\n",
      "Method          | Avg Time (s)    | RMSE (Error)   \n",
      "--------------------------------------------------\n",
      "PMLE (Ours)     | 0.4096          | 0.063112       \n",
      "GMLE (NR)       | 2.2574          | 0.063093       \n",
      "GMLE (GD)       | 15.6762         | 0.063259       \n",
      "==================================================\n",
      "解读：\n",
      "1. RMSE 越小说明估计越准。\n",
      "2. PMLE 的 RMSE 应该与 GMLE(NR) 几乎一致（渐近等效）。\n",
      "3. PMLE 的时间在大规模数据下应该显著少于 NR。\n"
     ]
    }
   ],
   "source": [
    "# --- 参数设置 ---\n",
    "N = 10**5      # 样本量\n",
    "p = 10         # 特征维度\n",
    "K = 11         # 类别数 (1个Major + 10个Rare)\n",
    "gamma = -0.5   # 稀有度参数\n",
    "nsimu = 50      # 仿真次数 (建议先跑5次看效果，正式跑可以改大)\n",
    "\n",
    "alpha = 40     # GD 学习率\n",
    "baseclass = 0\n",
    "K0_pval = 0.9  \n",
    "\n",
    "# --- 结果容器初始化 ---\n",
    "t_nr = np.zeros(nsimu)\n",
    "t_gd = np.zeros(nsimu)\n",
    "t_pmle = np.zeros(nsimu)\n",
    "\n",
    "# 存储每一轮的参数估计结果\n",
    "beta_hat_pmle = np.zeros([nsimu, p+1, (K-1)])\n",
    "beta_hat_nr   = np.zeros([nsimu, p+1, (K-1)])\n",
    "beta_hat_gd   = np.zeros([nsimu, p+1, (K-1)])\n",
    "\n",
    "# 生成真实参数 (Ground Truth)\n",
    "# 注意：beta_true 是固定的，我们看谁算出来的结果离它最近\n",
    "beta_true = beta_true_gen(N, p, K, gamma) \n",
    "\n",
    "print(f\"=== 开始仿真 ===\")\n",
    "print(f\"设置: N={N}, K={K}, p={p}, Rounds={nsimu}\")\n",
    "n_jobs = min(K-1, NUM_CPU)\n",
    "print(f\"并行后端: Joblib (loky), Workers={n_jobs}\")\n",
    "\n",
    "# 使用 tqdm 显示进度条\n",
    "for b in tqdm(range(nsimu), desc=\"Simulation Progress\"):\n",
    "    \n",
    "    # 1. 生成数据\n",
    "    np.random.seed(b) # 确保每一轮数据是随机生成的，但不同方法处理的是同一份数据\n",
    "    X = X_gen(N, p)\n",
    "    X = np.hstack([np.ones([N,1]), X]) # 增加截距项\n",
    "\n",
    "    # 计算概率并生成 Y\n",
    "    prob = np.exp(X @ beta_true) \n",
    "    prob = np.hstack([np.ones([N,1]), prob])  \n",
    "    prob = prob / np.sum(prob, 1).reshape([N,1])\n",
    "    prob_cumsum = np.cumsum(prob, 1)   \n",
    "    Y = (np.random.uniform(size=[N,1]) < prob_cumsum).astype(np.int16)\n",
    "    Y = np.argmax(Y, 1) \n",
    "    \n",
    "    # === 1. PMLE: Pairwise Maximum Likelihood (并行版) ===\n",
    "    t_start = time.time()\n",
    "    \n",
    "    idx_0 = np.where(Y == 0)[0]\n",
    "    X_0 = X[idx_0]\n",
    "    Y_0 = Y[idx_0]\n",
    "    \n",
    "    results = Parallel(n_jobs=n_jobs, backend='loky')(\n",
    "        delayed(solve_single_pair_joblib)(\n",
    "            X_0, Y_0,       \n",
    "            X[Y == k],      \n",
    "            Y[Y == k], \n",
    "            K0_pval\n",
    "        ) \n",
    "        for k in range(1, K)\n",
    "    )\n",
    "    \n",
    "    beta_hat_pmle[b] = np.array(results).T\n",
    "    t_pmle[b] = time.time() - t_start\n",
    "    \n",
    "    # === 2. GMLE: Newton-Raphson (标准牛顿法) ===\n",
    "    t_start = time.time()\n",
    "    beta_hat_nr[b], _, _ = mle_multilogistic_opt_ic(X, Y, K0_pval, baseclass=baseclass)\n",
    "    t_nr[b] = time.time() - t_start\n",
    "    \n",
    "    # === 3. GMLE: Gradient Descent (梯度下降法) ===\n",
    "    t_start = time.time()\n",
    "    beta_hat_gd[b], _, _ = gd_multilogistic_opt_ic(X, Y, K0_pval, baseclass, alpha)\n",
    "    t_gd[b] = time.time() - t_start\n",
    "    \n",
    "    # 实时打印三种方法的时间\n",
    "    # 如果不想刷屏，可以把 if b % 1 == 0 改成 if b % 5 == 0\n",
    "    tqdm.write(f\"Round {b+1}: PMLE={t_pmle[b]:.3f}s | NR={t_nr[b]:.3f}s | GD={t_gd[b]:.3f}s\")\n",
    "\n",
    "# ==========================================\n",
    "# 结果评估 (计算 RMSE)\n",
    "# RMSE: Root Mean Square Error (均方根误差)，越小越好\n",
    "# ==========================================\n",
    "\n",
    "def calc_rmse(beta_hat_array, beta_true):\n",
    "    # beta_hat_array: (nsimu, p+1, K-1)\n",
    "    # beta_true: (p+1, K-1)\n",
    "    # Numpy 会自动进行广播计算 (Broadcasting)\n",
    "    diff = beta_hat_array - beta_true\n",
    "    mse = np.mean(diff**2)\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "rmse_pmle = calc_rmse(beta_hat_pmle, beta_true)\n",
    "rmse_nr   = calc_rmse(beta_hat_nr, beta_true)\n",
    "rmse_gd   = calc_rmse(beta_hat_gd, beta_true)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"{'Method':<15} | {'Avg Time (s)':<15} | {'RMSE (Error)':<15}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'PMLE (Ours)':<15} | {np.mean(t_pmle):<15.4f} | {rmse_pmle:<15.6f}\")\n",
    "print(f\"{'GMLE (NR)':<15} | {np.mean(t_nr):<15.4f} | {rmse_nr:<15.6f}\")\n",
    "print(f\"{'GMLE (GD)':<15} | {np.mean(t_gd):<15.4f} | {rmse_gd:<15.6f}\")\n",
    "print(\"=\"*50)\n",
    "print(\"解读：\\n1. RMSE 越小说明估计越准。\\n2. PMLE 的 RMSE 应该与 GMLE(NR) 几乎一致（渐近等效）。\\n3. PMLE 的时间在大规模数据下应该显著少于 NR。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f53767b-c213-4778-9c25-d916405774ed",
   "metadata": {},
   "source": [
    "## 高维模拟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7684590d-3153-4e9f-b9cd-81b68e3bfeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在生成高维真实参数 Beta_true ...\n",
      "\n",
      "=== 开始高维仿真 (High-Dim) ===\n",
      "设置: N=100000, K=51, p=500, Rounds=2\n",
      "注: 由于维度过高 (Hessian矩阵 > 2.5万维), GMLE-NR 方法已被禁用。\n",
      "并行后端: Joblib (loky), Workers=20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877510a6b2bc4a609140d55d5359d6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HD Simulation Progress:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1: PMLE=92.109s | GD=157.979s\n",
      "Round 2: PMLE=94.634s | GD=168.552s\n",
      "\n",
      "============================================================\n",
      "High-Dimensional Result (N=100000, p=500, K=51)\n",
      "Method          | Avg Time (s)    | RMSE (Error)   \n",
      "------------------------------------------------------------\n",
      "PMLE (Ours)     | 93.3715         | 0.073824       \n",
      "GMLE (GD)       | 163.2655        | 0.073095       \n",
      "GMLE (NR)       | Failed (OOM)    | N/A            \n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # ==========================================\n",
    "    # 1. 高维参数设置 (High Dimensional Settings)\n",
    "    # ==========================================\n",
    "    N_hd = 10**5       # 样本量: 10万\n",
    "    p_hd = 500         # 特征维度: 500 (高维!)\n",
    "    K_hd = 51          # 类别数: 51 (多类!)\n",
    "    gamma_hd = -0.5    # 稀有度\n",
    "    \n",
    "    # 仿真次数\n",
    "    # 高维计算比较耗时，建议先设为 2 或 5 跑通流程\n",
    "    nsimu_hd = 2       \n",
    "    \n",
    "    alpha_hd = 40      # GD 学习率\n",
    "    baseclass_hd = 0\n",
    "    K0_pval_hd = 0.9\n",
    "\n",
    "    # ==========================================\n",
    "    # 2. 结果容器 (注意: 没有 NR 方法了)\n",
    "    # ==========================================\n",
    "    t_gd_hd = np.zeros(nsimu_hd)\n",
    "    t_pmle_hd = np.zeros(nsimu_hd)\n",
    "\n",
    "    # 参数估计结果矩阵 (维度变大)\n",
    "    # Shape: [nsimu, 501, 50]\n",
    "    beta_hat_pmle_hd = np.zeros([nsimu_hd, p_hd+1, (K_hd-1)])\n",
    "    beta_hat_gd_hd   = np.zeros([nsimu_hd, p_hd+1, (K_hd-1)])\n",
    "    \n",
    "    # 生成真实参数 (Ground Truth)\n",
    "    print(\"正在生成高维真实参数 Beta_true ...\")\n",
    "    beta_true_hd = beta_true_gen(N_hd, p_hd, K_hd, gamma_hd) \n",
    "\n",
    "    # ==========================================\n",
    "    # 3. 开始仿真\n",
    "    # ==========================================\n",
    "    print(f\"\\n=== 开始高维仿真 (High-Dim) ===\")\n",
    "    print(f\"设置: N={N_hd}, K={K_hd}, p={p_hd}, Rounds={nsimu_hd}\")\n",
    "    print(f\"注: 由于维度过高 (Hessian矩阵 > 2.5万维), GMLE-NR 方法已被禁用。\")\n",
    "    \n",
    "    # 并行设置\n",
    "    n_jobs_hd = min(K_hd-1, NUM_CPU)\n",
    "    print(f\"并行后端: Joblib (loky), Workers={n_jobs_hd}\")\n",
    "\n",
    "    for b in tqdm(range(nsimu_hd), desc=\"HD Simulation Progress\"):\n",
    "        \n",
    "        # --- 生成高维数据 ---\n",
    "        np.random.seed(b)\n",
    "        X = X_gen(N_hd, p_hd)\n",
    "        X = np.hstack([np.ones([N_hd,1]), X]) # 增加截距项\n",
    "\n",
    "        # 计算概率并生成 Y\n",
    "        # 注意：这里矩阵乘法运算量较大\n",
    "        prob = np.exp(X @ beta_true_hd) \n",
    "        prob = np.hstack([np.ones([N_hd,1]), prob])  \n",
    "        prob = prob / np.sum(prob, 1).reshape([N_hd,1])\n",
    "        prob_cumsum = np.cumsum(prob, 1)   \n",
    "        Y = (np.random.uniform(size=[N_hd,1]) < prob_cumsum).astype(np.int16)\n",
    "        Y = np.argmax(Y, 1) \n",
    "        \n",
    "        # === 1. PMLE: Pairwise Maximum Likelihood (并行) ===\n",
    "        t_start = time.time()\n",
    "        \n",
    "        # 提取 Major Class\n",
    "        idx_0 = np.where(Y == 0)[0]\n",
    "        X_0 = X[idx_0]\n",
    "        Y_0 = Y[idx_0]\n",
    "        \n",
    "        # 启动 50 个并行任务\n",
    "        # 每个任务只需要处理 p=500 的矩阵求逆，速度依然很快\n",
    "        results = Parallel(n_jobs=n_jobs_hd, backend='loky')(\n",
    "            delayed(solve_single_pair_joblib)(\n",
    "                X_0, Y_0,       \n",
    "                X[Y == k],      \n",
    "                Y[Y == k], \n",
    "                K0_pval_hd\n",
    "            ) \n",
    "            for k in range(1, K_hd)\n",
    "        )\n",
    "        \n",
    "        beta_hat_pmle_hd[b] = np.array(results).T\n",
    "        t_pmle_hd[b] = time.time() - t_start\n",
    "        \n",
    "        # === 2. GMLE: Gradient Descent (串行) ===\n",
    "        # 梯度下降不需要求大矩阵的逆，所以可以运行\n",
    "        # 但在高维下收敛可能很慢\n",
    "        t_start = time.time()\n",
    "        beta_hat_gd_hd[b], _, _ = gd_multilogistic_opt_ic(X, Y, K0_pval_hd, baseclass_hd, alpha_hd)\n",
    "        t_gd_hd[b] = time.time() - t_start\n",
    "        \n",
    "        # 打印本轮耗时\n",
    "        tqdm.write(f\"Round {b+1}: PMLE={t_pmle_hd[b]:.3f}s | GD={t_gd_hd[b]:.3f}s\")\n",
    "\n",
    "    # ==========================================\n",
    "    # 4. 结果评估 (计算 RMSE)\n",
    "    # ==========================================\n",
    "    def calc_rmse(beta_hat_array, beta_true):\n",
    "        diff = beta_hat_array - beta_true\n",
    "        mse = np.mean(diff**2)\n",
    "        return np.sqrt(mse)\n",
    "\n",
    "    rmse_pmle_hd = calc_rmse(beta_hat_pmle_hd, beta_true_hd)\n",
    "    rmse_gd_hd   = calc_rmse(beta_hat_gd_hd, beta_true_hd)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"High-Dimensional Result (N={N_hd}, p={p_hd}, K={K_hd})\")\n",
    "    print(f\"{'Method':<15} | {'Avg Time (s)':<15} | {'RMSE (Error)':<15}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'PMLE (Ours)':<15} | {np.mean(t_pmle_hd):<15.4f} | {rmse_pmle_hd:<15.6f}\")\n",
    "    print(f\"{'GMLE (GD)':<15} | {np.mean(t_gd_hd):<15.4f} | {rmse_gd_hd:<15.6f}\")\n",
    "    print(f\"{'GMLE (NR)':<15} | {'Failed (OOM)':<15} | {'N/A':<15}\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f4d4b0-e4b8-4dfa-ac50-07d653f823ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PMLE",
   "language": "python",
   "name": "pmle_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
